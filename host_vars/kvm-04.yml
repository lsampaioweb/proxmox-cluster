---
mac_bind:
  - {mac_address: "00:e0:4c:49:fb:b7", nic_name: "enp1board0"}
  - {mac_address: "00:e0:4c:68:03:b3", nic_name: "enp2lacp0"}
  - {mac_address: "50:e5:49:ac:39:a4", nic_name: "enp2lacp1"}
  - {mac_address: "00:00:00:00:00:05", nic_name: "enp2lacp2"}
  - {mac_address: "94:de:80:8e:ef:45", nic_name: "enp2lacp3"}
  - {mac_address: "a0:36:9f:40:3d:60", nic_name: "enp3sync0"}
  - {mac_address: "a0:36:9f:40:3d:62", nic_name: "enp3sync1"}

bond0_nic: "enp2lacp0 enp2lacp2 eth0 eth3"
wan_management_nic: "bond0"
wan_management_ip: "{{ ansible_host }}"
wan_management_netmask: "24"
wan_management_ip_and_netmask: "{{ wan_management_ip }}/{{ wan_management_netmask }}"
wan_management_gateway: "192.168.0.2"

lan_management_nic: "bond0.2"
lan_management_ip: "10.0.2.8"
lan_management_netmask: "28"
lan_management_ip_and_netmask: "{{ lan_management_ip }}/{{ lan_management_netmask }}"

cluster_nic: "bond0.3"
cluster_ip: "10.0.3.8"
cluster_netmask: "28"
cluster_ip_and_netmask: "{{ cluster_ip }}/{{ cluster_netmask }}"

vms_nic: "bond0.4"

ceph_ip: "10.0.5.8"
ceph_netmask: "28"
ceph_ip_and_netmask: "{{ ceph_ip }}/{{ ceph_netmask }}"

ceph_next_ip_01: "10.0.5.9"
ceph_next_netmask_01: "32"
ceph_next_ip_and_netmask_01: "{{ ceph_next_ip_01 }}/{{ ceph_next_netmask_01 }}"

ceph_next_ip_02: "10.0.5.10"
ceph_next_netmask_02: "32"
ceph_next_ip_and_netmask_02: "{{ ceph_next_ip_02 }}/{{ ceph_next_netmask_02 }}"

lvm: []

is_ceph_server: true

ceph_cluster_ip: "10.0.5.8"
ceph_cluster_netmask: "28"
ceph_cluster_ip_and_netmask: "{{ ceph_cluster_ip }}/{{ ceph_cluster_netmask }}"

ceph_devices:
  - {name: "/dev/nvme0n1", type: "nvme"}
  - {name: "/dev/nvme1n1", type: "nvme"}
  - {name: "/dev/nvme2n1", type: "nvme"}
  - {name: "/dev/nvme3n1", type: "nvme"}
  - {name: "/dev/sdb", type: "ssd"}
  - {name: "/dev/sdc", type: "ssd"}
  - {name: "/dev/sdd", type: "hdd"}

ceph_crush_rules:
  - {name: "nvme", type: "nvme"}
  - {name: "ssd", type: "ssd"}
  - {name: "hdd", type: "hdd"}

ceph_pools:
  - {name: "Ceph_Gold", crush_rule: "nvme"}
  - {name: "Ceph_Silver", crush_rule: "ssd"}
  - {name: "Ceph_Bronze", crush_rule: "hdd"}

ceph_default_pools_crush_rule:
  - {name: "device_health_metrics", crush_rule: "hdd"}
  - {name: "CephFS_Bronze_data", crush_rule: "hdd"}
  - {name: "CephFS_Bronze_metadata", crush_rule: "hdd"}

ceph_file_systems:
  - {name: "CephFS_Bronze", pg_num: "128"}
